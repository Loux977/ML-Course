{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search & Cross-Validation from Scratch\n",
    "\n",
    "Here I re-created the implementation of the **Grid Search with Cross Validation (CV)** seen in exercise `08_sklearn_grid_search` from scratch (without using Scikit-Learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('../datasets/diabetes.csv')\n",
    "\n",
    "diabetes = diabetes.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "selected_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "                     'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "X = diabetes[selected_features].values\n",
    "y = diabetes['Outcome'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform k-fold cross-validation manually\n",
    "def cross_validate(model, X, y, k):\n",
    "    fold_size = len(X) // k\n",
    "    scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Creating train/validation splits\n",
    "        X_val = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_val = y[i * fold_size:(i + 1) * fold_size]\n",
    "\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        scores.append(acc)\n",
    "        print(f\"  Fold {i+1}: Accuracy = {acc:.4f}\")  # Print accuracy for each fold\n",
    "\n",
    "    return np.mean(scores) # return average CV accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits.\n",
      "\n",
      "\n",
      "[1/24] Testing Params: C=0.001, penalty=l1, tol=0.1\n",
      "  Fold 1: Accuracy = 0.6557\n",
      "  Fold 2: Accuracy = 0.7213\n",
      "  Fold 3: Accuracy = 0.6066\n",
      "  Fold 4: Accuracy = 0.6639\n",
      "  Fold 5: Accuracy = 0.6475\n",
      "  Average CV Accuracy: 0.6590\n",
      "\n",
      "[2/24] Testing Params: C=0.001, penalty=l1, tol=0.001\n",
      "  Fold 1: Accuracy = 0.6557\n",
      "  Fold 2: Accuracy = 0.7213\n",
      "  Fold 3: Accuracy = 0.6066\n",
      "  Fold 4: Accuracy = 0.6639\n",
      "  Fold 5: Accuracy = 0.6475\n",
      "  Average CV Accuracy: 0.6590\n",
      "\n",
      "[3/24] Testing Params: C=0.001, penalty=l2, tol=0.1\n",
      "  Fold 1: Accuracy = 0.6557\n",
      "  Fold 2: Accuracy = 0.7213\n",
      "  Fold 3: Accuracy = 0.6066\n",
      "  Fold 4: Accuracy = 0.6639\n",
      "  Fold 5: Accuracy = 0.6475\n",
      "  Average CV Accuracy: 0.6590\n",
      "\n",
      "[4/24] Testing Params: C=0.001, penalty=l2, tol=0.001\n",
      "  Fold 1: Accuracy = 0.6557\n",
      "  Fold 2: Accuracy = 0.7213\n",
      "  Fold 3: Accuracy = 0.6066\n",
      "  Fold 4: Accuracy = 0.6639\n",
      "  Fold 5: Accuracy = 0.6475\n",
      "  Average CV Accuracy: 0.6590\n",
      "\n",
      "[5/24] Testing Params: C=0.01, penalty=l1, tol=0.1\n",
      "  Fold 1: Accuracy = 0.6557\n",
      "  Fold 2: Accuracy = 0.7213\n",
      "  Fold 3: Accuracy = 0.6066\n",
      "  Fold 4: Accuracy = 0.6639\n",
      "  Fold 5: Accuracy = 0.6475\n",
      "  Average CV Accuracy: 0.6590\n",
      "\n",
      "[6/24] Testing Params: C=0.01, penalty=l1, tol=0.001\n",
      "  Fold 1: Accuracy = 0.6557\n",
      "  Fold 2: Accuracy = 0.7213\n",
      "  Fold 3: Accuracy = 0.6066\n",
      "  Fold 4: Accuracy = 0.6639\n",
      "  Fold 5: Accuracy = 0.6475\n",
      "  Average CV Accuracy: 0.6590\n",
      "\n",
      "[7/24] Testing Params: C=0.01, penalty=l2, tol=0.1\n",
      "  Fold 1: Accuracy = 0.7787\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7131\n",
      "  Fold 4: Accuracy = 0.7787\n",
      "  Fold 5: Accuracy = 0.7705\n",
      "  Average CV Accuracy: 0.7639\n",
      "\n",
      "[8/24] Testing Params: C=0.01, penalty=l2, tol=0.001\n",
      "  Fold 1: Accuracy = 0.7869\n",
      "  Fold 2: Accuracy = 0.7705\n",
      "  Fold 3: Accuracy = 0.7131\n",
      "  Fold 4: Accuracy = 0.7541\n",
      "  Fold 5: Accuracy = 0.7623\n",
      "  Average CV Accuracy: 0.7574\n",
      "\n",
      "[9/24] Testing Params: C=0.1, penalty=l1, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7377\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.8115\n",
      "  Average CV Accuracy: 0.7738\n",
      "\n",
      "[10/24] Testing Params: C=0.1, penalty=l1, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8115\n",
      "  Fold 2: Accuracy = 0.7705\n",
      "  Fold 3: Accuracy = 0.7377\n",
      "  Fold 4: Accuracy = 0.7049\n",
      "  Fold 5: Accuracy = 0.7951\n",
      "  Average CV Accuracy: 0.7639\n",
      "\n",
      "[11/24] Testing Params: C=0.1, penalty=l2, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7131\n",
      "  Fold 4: Accuracy = 0.7377\n",
      "  Fold 5: Accuracy = 0.7951\n",
      "  Average CV Accuracy: 0.7689\n",
      "\n",
      "[12/24] Testing Params: C=0.1, penalty=l2, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7869\n",
      "  Fold 3: Accuracy = 0.7131\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.7869\n",
      "  Average CV Accuracy: 0.7656\n",
      "\n",
      "[13/24] Testing Params: C=1, penalty=l1, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8361\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7377\n",
      "  Fold 4: Accuracy = 0.7377\n",
      "  Fold 5: Accuracy = 0.8115\n",
      "  Average CV Accuracy: 0.7803\n",
      "\n",
      "[14/24] Testing Params: C=1, penalty=l1, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7295\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.8033\n",
      "  Average CV Accuracy: 0.7705\n",
      "\n",
      "[15/24] Testing Params: C=1, penalty=l2, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8361\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7295\n",
      "  Fold 4: Accuracy = 0.7377\n",
      "  Fold 5: Accuracy = 0.8115\n",
      "  Average CV Accuracy: 0.7787\n",
      "\n",
      "[16/24] Testing Params: C=1, penalty=l2, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7131\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.8033\n",
      "  Average CV Accuracy: 0.7672\n",
      "\n",
      "[17/24] Testing Params: C=10, penalty=l1, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8361\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7377\n",
      "  Fold 4: Accuracy = 0.7377\n",
      "  Fold 5: Accuracy = 0.8115\n",
      "  Average CV Accuracy: 0.7803\n",
      "\n",
      "[18/24] Testing Params: C=10, penalty=l1, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7705\n",
      "  Fold 3: Accuracy = 0.7213\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.8033\n",
      "  Average CV Accuracy: 0.7672\n",
      "\n",
      "[19/24] Testing Params: C=10, penalty=l2, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8361\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7377\n",
      "  Fold 4: Accuracy = 0.7377\n",
      "  Fold 5: Accuracy = 0.8115\n",
      "  Average CV Accuracy: 0.7803\n",
      "\n",
      "[20/24] Testing Params: C=10, penalty=l2, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7705\n",
      "  Fold 3: Accuracy = 0.7213\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.8033\n",
      "  Average CV Accuracy: 0.7672\n",
      "\n",
      "[21/24] Testing Params: C=100, penalty=l1, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8361\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7377\n",
      "  Fold 4: Accuracy = 0.7377\n",
      "  Fold 5: Accuracy = 0.8115\n",
      "  Average CV Accuracy: 0.7803\n",
      "\n",
      "[22/24] Testing Params: C=100, penalty=l1, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7705\n",
      "  Fold 3: Accuracy = 0.7213\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.8033\n",
      "  Average CV Accuracy: 0.7672\n",
      "\n",
      "[23/24] Testing Params: C=100, penalty=l2, tol=0.1\n",
      "  Fold 1: Accuracy = 0.8361\n",
      "  Fold 2: Accuracy = 0.7787\n",
      "  Fold 3: Accuracy = 0.7377\n",
      "  Fold 4: Accuracy = 0.7377\n",
      "  Fold 5: Accuracy = 0.8115\n",
      "  Average CV Accuracy: 0.7803\n",
      "\n",
      "[24/24] Testing Params: C=100, penalty=l2, tol=0.001\n",
      "  Fold 1: Accuracy = 0.8197\n",
      "  Fold 2: Accuracy = 0.7705\n",
      "  Fold 3: Accuracy = 0.7213\n",
      "  Fold 4: Accuracy = 0.7213\n",
      "  Fold 5: Accuracy = 0.8033\n",
      "  Average CV Accuracy: 0.7672\n",
      "\n",
      "Best Parameters: (1, 'l1', 0.1)\n",
      "Best Accuracy (training set): 0.78\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'tol': [0.1, 0.001]\n",
    "}\n",
    "\n",
    "# Generate all possible hyperparameter combinations\n",
    "param_combinations = list(itertools.product(param_grid['C'], param_grid['penalty'], param_grid['tol']))\n",
    "num_candidates = len(param_combinations)  # Total hyperparameter combinations\n",
    "cv_folds = 5  # Number of cross-validation folds\n",
    "total_fits = num_candidates * cv_folds  # Total model fits\n",
    "\n",
    "# Perform grid search with CV from Scratch\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "print(f\"Fitting {cv_folds} folds for each of {num_candidates} candidates, totalling {total_fits} fits.\\n\")\n",
    "for idx, params in enumerate(param_combinations):\n",
    "    C, penalty, tol = params\n",
    "\n",
    "    # Define model with current hyperparameters configuration to test\n",
    "    model = LogisticRegression(random_state=42, solver='saga', C=C, penalty=penalty, tol=tol)\n",
    "\n",
    "    print(f\"\\n[{idx+1}/{num_candidates}] Testing Params: C={C}, penalty={penalty}, tol={tol}\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    mean_cv_score = cross_validate(model, X_train_std, y_train, k=cv_folds)\n",
    "\n",
    "    print(f\"  Average CV Accuracy: {mean_cv_score:.4f}\")\n",
    "\n",
    "    # Update best model if the current one is better\n",
    "    if mean_cv_score > best_score:\n",
    "        best_score = mean_cv_score\n",
    "        best_params = params\n",
    "\n",
    "# Print best parameters\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "print(f\"Best Accuracy (training set): {best_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Evaluation:\n",
      "Best Hyperparameters: (1, 'l1', 0.1)\n",
      "Accuracy with Best Model (test set): 0.77\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        96\n",
      "           1       0.74      0.60      0.67        58\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.76      0.74      0.75       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n",
      "Confusion Matrix:\n",
      " [[84 12]\n",
      " [23 35]]\n"
     ]
    }
   ],
   "source": [
    "# Train the best model on the full training set\n",
    "best_model = LogisticRegression(random_state=42, solver='saga', C=best_params[0], \n",
    "                                penalty=best_params[1], tol=best_params[2], max_iter=1000)\n",
    "best_model.fit(X_train_std, y_train)\n",
    "\n",
    "# Make predictions on the standardized test data\n",
    "y_pred = best_model.predict(X_test_std)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal Model Evaluation:\")\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "print(f'Accuracy with Best Model (test set): {accuracy:.2f}')\n",
    "print('Classification Report:\\n', classification_report_str)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
